\cleardoublepage

\chapter*{Abstract}
\label{resumen}
\addcontentsline{toc}{chapter}{Abstract}

Artificial Intelligence has evolved significantly since its emergence in the late 1950s and its subsequent rise during the 1970s and 1980s with rule-based systems and approximate reasoning. The current resurgence of AI has brought forth generative models. Music generation is an emerging application within this new paradigm, supported by Variational Autoencoders (VAEs) and advanced Generative Adversarial Networks (GANs). This line of work has been strengthened by the growing availability of digital music data and the maturity of neural architectures applied to spectrogram processing.
    
This master's thesis addresses the generation of personalized music conditioned by musical genre, combining various generative approaches within a system capable of evaluating artificially generated musical pieces. The process is articulated through a structured pipeline that spans from the collection and transformation of audio files into spectral representations to the training of adversarial generative models capable of reconstructing and generating music from latent noise and explicit genre input.

Initially, VAE-based models are developed to explore the compression and reconstruction of spectrograms, aiming to capture coherent musical structures. Subsequently, a GAN system with a hybrid Transformer-based architecture is integrated to enhance the creative capacity and perceptual quality of the generated pieces. Both approaches complement each other in their pursuit of more flexible and meaningful musical synthesis.

The combination of agile development methodologies with modern programming languages and modeling frameworks results in a system that unifies generative techniques, spectral representation, and genre conditioning.
