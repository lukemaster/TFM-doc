% MÉTODOS Y MATERIALES

\cleardoublepage

\chapter{Materiales y métodos}

\section{Materiales}
Seguidamente se enumera todo el material que se ha utilizado para la realización de este trabajo.

\subsection{Datos}
\label{materiales-datos}

En la sección \textbf{Tratamiento de datos}\ref{tratamiento-datos} del capítulo anterior se puede consultar una mención a los dataset que se van a utilizar y que seguidamente se pasan a describir más en profundidad.

Se tratan de datasets cuyos elementos están etiquetados por género. Cada uno de estos dataset aporta variedad musical en \emph{MP3} y aumentan la cantidad de muestras disponibles. Cuentan, teóricamente, con un mínimo de calidad de audio y duración determinados. Entre los tres, aseguran que con la merma que se pueda producir de la limpieza del dataset, en cuanto a piezas musicales que no cumplan las especificaciones, corruptas, etc., el volumen final resultante es un dataset lo suficientemente amplio como para poder generalizar características de cada género musical contenido.

\subsubsection{FMA (Free Music Archive) Dataset}

Con un tamaño de más de 100,000 pistas y 160 géneros, se trata de un \emph{dataset} enorme, que cuenta con piezas representativas de cada género. Está respaldado por un repositorio \href{https://github.com/mdeff/fma}{GitHub} que además provee unos \emph{scripts} con ejemplos y algoritmos en \emph{Python}, que extraen información sobre estructura, contenido, organización, etc., del conjunto de datos.

Todas las pistas se encuentran en formato \emph{MP3} (44.1 kHz, 128-320 kbps). Existen tres variantes en cuanto al tamaño del conjunto de datos:

\begin{itemize}
    \item \textbf{FMA Small:} 8,000 pistas, 8 géneros, aproximadamente 1GB.
    \item \textbf{FMA Medium:} 25,000 pistas, 16 géneros, aproximadamente 10GB.
    \item \textbf{FMA Large:} 106,000 pistas, 161 géneros, aproximadamente 100GB. \textbf{(Esta ha sido la variante utilizada).}
\end{itemize}

Se incluyen metadatos como título, artista, álbum, y etiquetas de género. Los géneros musicales están repartidos en niveles de manera jerárquica, siendo los géneros \emph{parent} de primer orden los siguientes:

\begin{multicols}{4}
\begin{itemize}
    \item Blues
    \item Classical
    \item Country
    \item Disco
    \item Hip-Hop
    \item Jazz
    \item Metal
    \item Pop
    \item Reggae
    \item Rock
\end{itemize}
\end{multicols}

\subsubsection{Million Song Dataset}

Se trata de un \emph{dataset vivo}. De base, cuenta con 1500 ficheros en formato \emph{MP3}, distribuidos en 15 categorías de género. Sin embargo, \href{https://www.kaggle.com/datasets/undefinenull/million-song-dataset-spotify-lastfm}{este conjunto de datos} puede hacerse tan grande como se necesite, pues viene acompañado de unos ficheros \emph{Python} que realizan una integración con servicios como Spotify y Last.fm. Además de eso, la sincronización con estos dos servicios brinda acceso a metadatos sobre popularidad, características del sonido y etiquetas de géneros.

Así pues, se podría decir que este \emph{dataset} brinda la posibilidad de tener ``toda'' la música de la red disponible para trabajar con ella.

Los géneros de los que se dispone son:
\begin{multicols}{4}
\begin{itemize}
    \item Electronic
    \item Rock
    \item Pop
    \item Folk
    \item Jazz
    \item Blues
    \item Country
    \item Reggae
    \item Latin
    \item R\&B
    \item World
    \item Rap
    \item Punk
    \item New Age
    \item Metal
\end{itemize}
\end{multicols}

\subsubsection{MTG-Jamendo Dataset}

Este \emph{dataset} cuenta con más de 50,000 pistas y 190 géneros, en ficheros \emph{MP3} de 320 kbps . Enorme donde las haya, esta librería fue desarrollada para tareas de etiquetado automático de música. Contiene un conjunto de etiquetas entre las que se encuentran: géneros musicales, instrumentos, emociones y temas. Viene respaldado por un repositorio \href{https://github.com/MTG/mtg-jamendo-dataset}{GitHub} que provee de scripts para su descarga y manejo, así como información sobre su contenido e información estadística.

Los géneros que se pueden encontrar, entre otros, son:
\begin{multicols}{4}
\begin{itemize}
    \item Electronic
    \item Rock
    \item Pop
    \item Folk
    \item Jazz
    \item Hip-Hop
    \item Classical
    \item Reggae
    \item Ska
    \item Swing
    \item Fusion
    \item Easy Listening
    \item Opera
    \item Gospel
    \item Holiday
    \item Comedy
    \item Spoken Word
    \item Podcast
    \item Sound Effects
\end{itemize}
\end{multicols}

Dentro de las modalidades de \emph{dataset} que provee este repositorio, se ha elegido \emph{autotagging\_moodtheme}, que provee ficheros de 30 segundos de duración con etiqueta de género, entre otras.

\subsubsection{Inteligencia Artificial, datasets, música generada y derechos de autor}
Sin querer, ni poder, entrar en una profunda y correcta disertación sobre los riesgos legales que se pueden esconder tras el uso de fragmentos de audio, para además generar audio nuevo, que en cierto modo está condicionado por ellos, sí que es posible emprender una reflexión ética.

Hay dos ideas fundamentales a las que atender, en este ámbito:
\begin{itemize}
    \item \textbf{Autoría y uso de fragmentos originales:} los fragmentos de audio contenidos en los datasets, evidentemente, han sido creados por alguna o varias, personas; además de la autoría, su propiedad pueda estar ligada a ella o no y establecerse un uso privativo o acotado del contenido, o no hacerse.
    \item \textbf{Generación de música a partir de datos creados previamente:} no es tanto el problema de \emph{quién es el propietario o autor de la obra}, sino en qué medida eso que se ha creado nuevo, se parece a algo que ya existiera antes y en qué grado podría ser atribuible al autor primigenio de la obra u obras antecedentes, observadas en el dataset.
\end{itemize}

En la legislación europea, una obra creada exclusivamente por una máquina no tiene autor protegido por \emph{copyright}, al no haber intervención humana creativa. Pero: ¿y si hubiera intervención artística explícita, programada en el proceso? ¿Podría ser acaso, el desarrollador del software, el autor de la obra? ¿podría serlo el equipo de desarrollo o la compañía?
... ¿Y dónde ha quedado la autoría de los fragmentos originales del dataset? ¿Se podría ``generar'' un derecho de autor privativo a partir de fragmentos de obras cedidas libremente?
Esto último ya ocurre con el uso de \emph{software libre}, que es tomado como base, modificado y vendido como software privativo... ¿Acaso la música generada por Inteligencia Artificial tiene, debido a su ente creador, características de software...?

Son más las preguntas que las respuestas en un debate tan interesante como la propia generación de audio.

\subsection{Software}

Para el desarrollo de este trabajo se han utilizado múltiples y diversos programas, desde el momento en que se inició este mismo document, hasta que se produzca la ``puesta en producción'' de la aplicación de usuario que permita el uso del modelo de Inteligencia Artificial.

Los recursos de tipo \emph{Software} utilizados son:

\begin{itemize}
    \item VisualStudio Code. Versión 1.97.2. Entorno de desarrollo de este mismo manual y manejo de datasets y scripts de \emph{Python}.
    \item TextShop. Version 5.49 (5.49). Compilador \LaTeX.
    \item Git. Versión 2.39.3 (Apple Git-145). Gestor de versiones de código fuente para los ficheros de código de este mismo manual y del software desarrollado.
    \item GitHub. Repositorio ``en la nube'' de código fuente.
    \item Draw.io. Editor de diagramas UML.
    \item reMarkable for MacOS. Versión 3.17.0 (906). Software de sincronización del dispositivo reMarkable 2.
    \item Mozilla Firefox. Versión 135.0.1 (64-bit). Explorador de Internet utilizado para el acceso a Jupyter Lab.
    \item Ubuntu 24.04.2 LTS.
    \item Jupyter (Notebook and Lab). Versión 7.2.2.
    \item Python Version: 3.12.7 (major=3, minor=12, micro=7, releaselevel='final', serial=0) | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:27:36) [GCC 11.2.0]
    \item Librería de Ptyhon \emph{Torch}. Version: 2.6.0+cu124. En el apéndice \ref{apendice-a:paquetes} se pude consultar la lista de todos los paquetes y versiones disponibles para el desarrollo.
    \item CUDA Version: 12.4
    \item cuDNN Version: 90100
    \item NVIDIA Driver Version: 550.127.08
    \item NCCL Version: (2, 21, 5)
\end{itemize}

\subsection{Hardware}

El hardware usado para el desarrollo de este TFM ha sido:

\begin{itemize}
    \item Ordenador \textbf{MacBook Pro 15 pulgadas, 2017.}
    \begin{itemize}
        \item Intel Core i7 2.8 GHz Quad-Core.
        \item 16 GB LPDDR3 2133 MHz.
        \item Intel HD Graphics 630 - Radeon PRO 555 2 GB PCIe.
        \item HD SSD 500 GB.
    \end{itemize}
    \item Ordenador \textbf{Asus ROG Strix G16 G614JIR-N4004 - Gaming 16 pulgadas, 2024.}
    \label{ASUS}
    \begin{itemize}
        \item Intel Core i9-14900HX.
        \item 32 GB LPDDR3 2133 MHz.
        \item NVIDIA RTX 4070 8GB Mobile.
        \item HD SSD 1 TB.
    \end{itemize}
    \item Paper tablet \textbf{reMarkable 2.}
    \item Calculadora \textbf{Texas Instruments TI-92 Plus.}
\end{itemize}

Dada la filia con el sistema operativo de Apple, se ha utilizado un Apple MacBook Pro para todo el proceso de escritura de documentación y como terminal de programación, siendo usado como interfaz con el otro ordenador ASUS, usado como nodo de procesamiento para el entrenamiento de los modelos de Inteligencia Artificial.

En las referencias \cite{geeksforgeeks2025jupyter} y \cite{vscode2025jupyter} se puede consultar cómo se ha configurado el ``servidor de procesamiento'' basado en \emph{Jupyter Lab}, instalado en la máquina ASUS\ref{ASUS}, en un Sistema Operativo Ubuntu 24.04.2 LTS.

En la imagen \ref{fig:jupyter-diagram} se pude ver un diagrama de cuáles son los accesos posible que brinda el servidor Jupyter para poder ejecutar el código Python de un situado en un ordenador, desde otro; o para poder directamente ejecutar el código Python situado en un ordenador (MacBook), en otra máquina distinta (ASUS), instanciando el entorno Python de esta otra máquina, a través del puerto configurado.

Para que el contexto de ejcución de Python encuentre en el PC ASUS los ficheros de código fuente alojados y editables en el MacBook Pro, se utiliza el sistem de archivos \emph{Secure SHell FileSystem (SSHFS)}.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{images/jupyter-diagram.png}
\caption{Diagrama de conexión hardware.}
\label{fig:jupyter-diagram}
\end{figure}

Jupyter Lab estará esperando detrás del puerto 8888 de la máquina ASUS, la cual podrá ser instanciada por VistualStudio Code como Jupyter kernel o ser accesible vía explorador de Internet, pudiendo usar el entorno de edición y ejecución web que el servicio provee.

De esta manera se consigue usar toda la potencia de una máquina, desde la comodidad de uso y cercanía que brinda la otra.

\section{Metodología}

Para el desarrollo de este TFM y del software que lo acompaña, se han barajado 3 maneras, \emph{frameworks} o métodos de emprender y encaminar esta labor, de manera rigurosa, estructurada y ordenada. Los nombres que se han manejado han sido:
\begin{itemize}
    \item CRSIP-ML(Q): Cross Industry Standard Process for Machine Learning with Quality Assurance
    \item TDSP: Team Data Science Process
    \item Scrum: del rugby, ideal que significa trabajo en equipo y rápida respuesta de adaptación.
\end{itemize}

Cada una de estas tres herramientas aporta valor a cada uno de los pasos que se puedan llevar a cabo. Haciendo un análisis más profundo y tal y como se explica en la entrada web\cite{TDSP-PM}, se podría decir que \emph{TDSP} podría ser la combinación de \emph{Scrum} y \emph{CRISP-DM} (Cross Industry Standard Process for Data Mining. En el caso de proyectos de Machine Learning, CRISP-ML(Q) parte de la misma filosfía y se adapta a las necesidades específicas de este tipo de trabjos). Así pues, dado que todo lo referente a gestión de equipo y recursos en paralelo es innecesario, pues este trabajo se realiza por una sola persona, se ha decidido tomar un combinación de \textbf{CRISP-ML(Q)} y \textbf{Scrum}, que permita ser tan riguroso como el primero de ellos y tan ágil y potente en cuanto a herramientas, como el segundo.

\subsection{CRISP-ML(Q)}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/crisp-ml-process.jpg}
    \caption{Diagrama de flujo usado en el desarrollo. Tomado de \cite{crispml}.}
    \label{fig:crispml-q-diagram}
  \end{figure}

\emph{CRISP-ML(Q)} conforma un marco estructurado para el desarrollo de proyectos de Machine Learning. Se compone de seis fases:

\begin{enumerate}
    \item \textbf{Comprensión del negocio}: Definir el problema y los objetivos del modelo.
    \item \textbf{Comprensión de los datos}: Recopilación y exploración inicial de los datos.
    \item \textbf{Preparación de los datos}: Limpieza, transformación y selección de variables.
    \item \textbf{Modelado}: Entrenamiento y optimización de modelos de Machine Learning.
    \item \textbf{Evaluación}: Validación de métricas y análisis del rendimiento.
    \item \textbf{Implementación y monitoreo}: Despliegue del modelo y seguimiento en producción.
\end{enumerate}

En la imagen\ref{fig:crispml-q-diagram} se puede ver cómo será el diagrama de flujo del desarrollo a seguir con este método.

\subsection{Scrum}

\emph{Scrum} es un framework que proporciona herramientas para la gestión ágil de proyectos de manera iterativa, dividiendo el trabajo en sprints (iteraciones cortas de 1-2 semanas). Las herramientas de \emph{Scrum} que se tomen para este proyecto serán:

\begin{itemize}
    \item \textbf{Product Backlog}: Lista priorizada de tareas a realizar.
    \item \textbf{Sprints}: Iteraciones donde se completan tareas específicas. Semanales.
    \item \textbf{Sprint Reviews}: Evaluaciones de cada sprint (semana o bisemanal) con la tutora de este TFM.
\end{itemize}

\subsection{Integración de CRISP-ML(Q) y Scrum}

A continuación, se detalla la planificación del TFM en base a estos marcos metodológicos.

\subsection{Product Backlog (Pila de producto)}

Las tareas que se han de llevar a cabo para completar el TFM, incluidos desarrollo de la documentación, software y evaluación y mantenimiento, se han organizado en el siguiente \emph{backlog}:

\input{tablas/table7}

\clearpage
\input{tablas/table-pila-producto}
\clearpage
\input{tablas/table-sprint}
Estableciendo las ``rondas'' iterables de progreso en \emph{sprints} de Scrum, el siguiente \emph{kanban} ilustra el estado ``actual'' del progreso de este trabajo:
\input{tablas/table-kanban}
%\input{tablas/table-kanban-sprints}
\clearpage
Como se puede apreciar, al haber un sólo desarrollador para el proyecto, no se han establecido y etiquetado asignaciones de tareas a recursos.

Además, dado el predominante carácter didáctico y explorativo del trabajo, no se ha querido (ni podido, pues una sola persona no debería estimar esfuerzos de tareas) llevar a cabo una estimación de coste o esfuerzo en cada una de las tareas.

Esto podría dar lugar a sprints desbalanceados, pero siendo francos y dada la necesidad imperiosa de conciliación familiar, laboral y estudiantil, marcar sprints rígidos a cumplir sería totalmente imposible de cumplir.

\subsection{Planificación del TFM}

Llegado a este punto, se ha hecho un ejercicio de recabado y asunción perpleja del método y pasos que hasta ahora se han ido siguiendo. Visto con perspectiva, desde el inicio de esta memoria se ha trabajado siguiendo los pasos detallados en \emph{CRISP-ML(Q)} y que se verán a continuación:

\input{tablas/table8}
Cada una de estas fases se ha dividido en \emph{sprints} de \emph{Scrum}, señalizados por un color distinto en el \emph{kanban}, lo que permite ver de manera directa el estado de cada \emph{sprint}.

Expuestas las fases de la planificación, se procede con el plan.

\subsubsection{Comprensión del negocio}

El objetivo del TFM es desarrollar un modelo basado en redes generativas adversariales (GANs) capaz de generar música personalizada en formato MP3. Se pretende que el modelo genere piezas musicales dentro de géneros específicos, con coherencia armónica y estructural.

Para ello, se han identificado los siguientes desafíos clave:
\begin{itemize}
    \item Disponibilidad y estructuración de datasets de música en formato MP3.
    \item Extracción y representación de características musicales relevantes bajo espectrogramas.
    \item Generar un modelo basado en Inteligencia Artificial que sea capaz de asociar características de la música, recogidas en los espectrogramas y asociarlas a un género aportado con cada ejemplo.
    \item Que ese mismo modelo de ``inteligente'' sea capaz de generar música aportando solamente el género requerido.
    \item Evaluación de la calidad de las composiciones generadas mediante métricas objetivas y subjetivas.
    \item Implementación de una interfaz para la generación de música personalizada.
\end{itemize}

Se justifica este trabajo en función del auge de los modelos generativos en el ámbito musical y la creciente demanda de herramientas que permitan la generación de contenido musical adaptado a los gustos del usuario.

\subsubsection{Comprensión de los datos}

El dataset utilizado para entrenar el modelo se compone de archivos MP3 extraídos de bases de datos como \textit{Free Music Archive} y \textit{MTG-Jamendo}. Estas fuentes proporcionan pistas en diferentes géneros, etiquetadas con metadatos detallados.

Se lleva a cabo un análisis exploratorio para comprender la estructura de los datos, incluyendo:
\begin{itemize}
    \item Distribución de duraciones y características tonales.
    \item Análisis espectral de los archivos de audio mediante espectrogramas y MFCCs (Mel-Frequency Cepstral Coefficients).
    \item Identificación de posibles sesgos en la distribución de géneros y calidad del audio.
\end{itemize}

Se detecta la necesidad de normalización y preprocesamiento de los archivos para garantizar la calidad del entrenamiento del modelo.

\subsubsection{Preparación de los datos}

Se implementa un pipeline de procesamiento de audio que incluye las siguientes etapas:
\begin{itemize}
    \item Conversión de los archivos MP3 en espectrogramas.
    \item Normalización de amplitudes y ajuste de la frecuencia de muestreo para uniformar los datos.
    \item Se probarán ventanas de \emph{sample} de audios de entre 10 - 25 y 40 milisegundos (se atenderá al criterio de calidad de generación obtenida y al consumo de recursos, capacidad y estabilidad del hardware disponible).
\end{itemize}

Además de esto, es conocido que, por muy bueno que pueda llegar a ser un conjunto de datos, \emph{no es oro todo lo que reluce}. Se presupone que se encontrarán piezas con duración dispar (de entre 29.5 y 30 segundos), que habrán de acotarse para que el tamaño del \emph{input} sea homogéneo.

También se prevee encontrar ficheros corruptos, bien por estar mal de origen, problemas en la descarga, descompresión de datos, copia, etc., y ficheros que no se encuentren y que estén descritos en los metadatos. Todo esto será controlado en aras de obtener una alimentación lo más favorable y exenta de errores posible.

Conocidos los problemas de tratar con un set de datos, ahora sume la siguiente discrepancia. Tómese el siguiente ejemplo:

\begin{itemize}
    \item Género rock
    \begin{itemize}
        \item dataset A: etiqueta \emph{Rock} con identificador \textbf{1}
        \item dataset B: etiqueta \emph{rock} con identificador \textbf{26}
        \item dataset C: etiqueta \emph{ROCK} con identificador \textbf{39}
    \end{itemize}
    \item Género pop
    \begin{itemize}
        \item dataset A: etiqueta \emph{Pop} con identificador \textbf{2}
        \item dataset B: etiqueta \emph{pop} con identificador \textbf{15}
        \item dataset C: etiqueta \emph{PoP} con identificador \textbf{8}
    \end{itemize}
    \item ...
\end{itemize}

La idea queda clara: es necesario homogeneizar las etiquetas, tanto en título, como en identificador y establecer un formato común de dupla \emph{título} \textbf{\#id}. Se usará la funcion \emph{lower} para obtener el texto en minúsuculas y se hará un nuevo mapa de idenficiadores y un traductor de identificador del sistema, a cada uno de los dataset.

Estos pasos aseguran que el modelo aprenda patrones relevantes sin sesgos introducidos por diferencias en la calidad de grabación o características técnicas de los archivos de audio.

\subsubsection{Modelado}

Es práctica habitual en todos los ámbitos de la vida en que se asume un riesgo desconocido, en algo importante, que se tengan a mano diversas soluciones posibles, candidatas a resolver el problema.

Pero si además, esas soluciones se configuran de manera que sean capaces de retroalimentarse y de servir de soporte entre ellas, supondría estar, desde el momento ``0'' del desarrollo, trabajando en una solución y mejorando o dando pie a otra, empleando el mismo esfuerzo.

Pues eso es lo que se pretende. Los modelos a entrenar serán:
\begin{itemize}
    \item VAE: mucho más estable y fácil de entrenar, el VAE marcará el preludio de toda la limpieza, adaptación y carga de datos para su entrenamiento, sirviendo de trampolín para el siguiente modelo.
    \item GAN - Transformer: inestable, costoso de entrenar y difícil de programar, partirá de los \emph{dataset} ya limpios y listos para ser tratados en entrenamiento, que usó el VAE y además la cadlidad de las piezas generadas, será medida con este modelo anterior, sirviendo esta métrica para evaluar la evolución de este nuevo y más potente modelo.
\end{itemize}

El modelo generador propuesto se basa en una arquitectura de redes generativas adversariales (GANs) adaptadas a la generación de secuencias de audio en formato MP3. Se diseñan los siguientes componentes:
\begin{itemize}
    \item \textbf{Generador:} Recibe una entrada aleatoria y genera espectrogramas sintéticos, que luego son convertidos en archivos de audio mediante un vocoder neuronal.
    \item \textbf{Discriminador:} Evalúa la autenticidad de los espectrogramas generados, comparándolos con fragmentos reales del dataset.
\end{itemize}

Se experimenta con distintas configuraciones, incluyendo GANs convencionales y variantes como Wasserstein-GAN (WGAN) para mejorar la estabilidad del entrenamiento. También se incorpora un Transformer en la arquitectura del generador para reforzar la coherencia temporal de las secuencias generadas.

\subsubsection{Evaluación}

La evaluación del modelo se realiza desde dos enfoques complementarios:
\begin{itemize}
    \item \textbf{Métricas objetivas:} Se analizan características acústicas como la similitud espectral entre las composiciones generadas y las piezas originales del dataset.
    \item \textbf{Métricas subjetivas:} Se realiza una prueba con oyentes humanos para evaluar la percepción de calidad y coherencia de las piezas generadas.
\end{itemize}

Se establecen comparaciones con modelos previos como \textit{MusicVAE} y \textit{MuseGAN} para contextualizar los resultados obtenidos.

\subsubsection{Implementación y monitoreo}

El modelo final se despliega en una interfaz interactiva donde los usuarios pueden generar música personalizada ajustando parámetros como:
\begin{itemize}
    \item Género musical deseado.
    \item Complejidad rítmica y armónica.
    \item Instrumentación preferida.
\end{itemize}

Se establece un sistema de monitoreo que recopila datos sobre el uso del modelo y permite la mejora continua mediante aprendizaje activo. Se documenta todo el proceso para garantizar la reproducibilidad y facilitar futuras mejoras en la arquitectura del modelo.

\section{UML}

\input{UML/analisis}
\input{UML/especificacion-modelo-de-clases}
\input{UML/diagramas-de-secuencia}
\input{UML/especificacion-requisitos-interfaz}
\input{UML/diseño-de-clases}
\input{UML/diagrama-de-paquetes}
\input{UML/diseño-de-la-interfaz}
